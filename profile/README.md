# Welcome to Prediction Guard

<p align="center">
  <img src="https://beta.predictionguard.com/pgsuccess.png" width="65%" height="65%" title="Prediction Guard"
</p>

Dealing with unruly output from Large Language Models (LLMs)? Get typed, structured and compliant output from the latest models with [Prediction Guard](https://www.predictionguard.com) and scale up your production AI integrations.

## How it Works

<picture align="center">
  <source media="(prefers-color-scheme: dark)" srcset="/images/feature1dark.png" width="75%" height="75%">
  <img src="/images/feature1light.png" width="75%" height="75%">
</picture>

Boost the performance of open access models like Falcon, MPT, Camel, etc. to GPT levels by guiding output structures and types.
### Control the Output of LLMs
  
Prediction Guard lets you enforce structure (e.g., valid JSON) and types (integer, float, boolean, etc.) on the output of the latest and greatest LLMs.
  
  * **Efficient** - Why waste days engineering around unreliable text blob output. Get reliable outputs that can be immediately integrated into enterprise systems.
  * **Performant** - Boost the performance of open access models like Falcon, MPT, Camel, etc. to GPT levels by guiding output structures and types.

<picture align="center">
  <source media="(prefers-color-scheme: dark)" srcset="/images/feature2dark.png" width="75%" height="75%">
  <img src="/images/feature2light.png" width="75%" height="75%">
</picture>
  
### Overcome AI Compliance Issues
  
Models hosted by Prediction Guard can be integrated in a SOC 2 Type II and HIPAA compliant manner, allowing you to delight your customers AND your corporate counsel.

* **Private** - Prevent leakages of IP and PII to public AI APIs with questionable terms. Prediction Guard does not store data you send to LLMs.
* **Validated** - Squash model hallucinations that might get you in hot water. Take advantage of easy-to-use checks on the consistency, factuality, and toxicity of LLM outputs.

<picture align="center">
  <source media="(prefers-color-scheme: dark)" srcset="/images/feature3dark.png" width="75%" height="75%">
  <img src="/images/feature3light.png" width="75%" height="75%">
</picture>

### Integrate and Ensemble the Latest Models

Let us do the hard work of hosting all the latest open and closed models in a controlled manner (Falcon, MPT, Camel, Pythia, OpenAI, etc.). You can then easily swap between models and ensemble them via a consistent, OpenAI-like, API.

* **Consistent** - All of our models can be called, controlled, and even ensembled via a consistent API. Try new models with zero integration cost and always be SOTA!
* **Relevant** - Look like a rock star when your leadership asks if you are using the latest AI model. We can keep your secret that this kind of integration takes 5 minutes.

<picture align="center">
  <source media="(prefers-color-scheme: dark)" srcset="/images/feature4dark.png" width="75%" height="75%">
  <img src="/images/feature4light.png" width="75%" height="75%"> 
</picture>

### Integrate with Popular Frameworks

Take your application to the next level by combining the controlled and compliant LLMs of Prediction Guard with the chaining, retrieval, agents, and evaluation available in popular open source frameworks.

* **Langchain** - Prediction Guard is available as an LLM wrapper in LangChain.
* **LlamaIndex** - Data retrieval and LLM evaluation from LlammaIntex (GPT Index) works out-of-the-box!

## Demos

If your interested in trying Prediction Guard, check out our [docs](https://docs.predictionguard.com).
